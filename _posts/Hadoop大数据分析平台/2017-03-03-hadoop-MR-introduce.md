---
layout: post
title: MapReduce原理与设计思想
category: Hadoop大数据分析平台
tags: Hadoop 大数据 数据挖掘 机器学习
keywords: 蓝桥 lanqiao 教程 Hadoop 大数据 数据挖掘 机器学习
description: 本文将带领大家了解MapReduce原理和设计思想，原理的学习非一蹴而就，所以这篇文档至少要看三遍：粗看一遍，实践后再看一遍，遇到思维瓶颈时再看一遍。
author: 郑未
---

# MapReduce是什么？

MapReduce是一种编程范式，可以利用集群环境的成千上万台服务器实现强大的可伸缩性。

MapReduce一次最早源于函数式编程，由Google在一篇名为“MapReduce：Simplified Data Processing on Large Clusters”的文章中率先提出。

使用MapReduce范式时，重点是编写两个函数：

map()
	
  过滤和聚集数据。

reduce()

  根据map()生成的键完成归约、分组和总结。

![MapReduce执行过程的简单视图](/public/img/hadoop/Snip20170530_1.png)

这两个函数定义如下

    map: (k1; v1) →[(k2; v2)]

输入：键值对(k1; v1)表示的数据

处理：文档数据记录(如文本文件中的行，或数据表格中的行)将以“键值对”形式传入map函数；map函数将处理这些键值对，并以另一种键值对形式输出一组键值对作为中间结果：`[(k2; v2)]`

输出：键值对`[(k2; v2)]`表示的一组中间数据

主节点根据唯一的键将中间结果进行洗牌和聚集，然后再一次重新分布到工作节点。

    reduce: (k2; [v2])→[(k3; v3)]

输入： 洗牌后的一个键和值列表`(k2; [v2])`

处理：对传入的中间结果列表数据进行某种整理或进一步的处理,并产生最终的某种形式的结果输出`[(k3; v3)]`

输出：最终输出结果`[(k3; v3)]`

![MapReduce](/public/img/hadoop/MapReduce.jpeg)

各个map函数对所划分的数据并行处理，从不同的输入数据产生不同的中间结果输出

各个reduce也各自并行计算，各自负责处理不同的中间结果数据集合。进行reduce处理之前,必须等到所有的map函数做完，因此,在进入reduce前需要有一个同步障(barrier);这个阶段也负责对map的中间结果数据进行收集整理(aggregation & shuffle)处理,以便reduce更有效地计算最终结果—最终汇总所有reduce的输出结果即可获得最终结果.

# MapReduce的简单解释

回家后，我的妻子（Supriya）问道：“你的会开得怎么样？”我说还不错。 接着她又问我会议是的内容是什么(她不是从事软件或编程领域的工作的)。我告诉她说MapReduce。“Mapduce，那是什么玩意儿？”她问道： “跟地形图有关吗？”我说不，不是的，它和地形图一点关系也没有。“那么，它到底是什么玩意儿？”妻子问道。 “唔…让我们去Dominos(披萨连锁)吧，我会在餐桌上跟你好好解释。” 妻子说：“好的。” 然后我们就去了披萨店。


![mapreduce原理](/public/img/hadoop/1321-thumb_mapreduce.png)

我们在Domions点餐之后，柜台的小伙子告诉我们说披萨需要15分钟才能准备好。于是，我问妻子：“你真的想要弄懂什么是MapReduce？” 她很坚定的回答说“是的”。 因此我问道：

我： 你是如何准备洋葱辣椒酱的？（以下并非准确食谱，请勿在家尝试）

妻子： 我会取一个洋葱，把它切碎，然后拌入盐和水，最后放进混合研磨机里研磨。这样就能得到洋葱辣椒酱了。

妻子： 但这和MapReduce有什么关系？

我： 你等一下。让我来编一个完整的情节，这样你肯定可以在15分钟内弄懂MapReduce.

妻子： 好吧。

我：现在，假设你想用薄荷、洋葱、番茄、辣椒、大蒜弄一瓶混合辣椒酱。你会怎么做呢？

妻子： 我会取薄荷叶一撮，洋葱一个，番茄一个，辣椒一根，大蒜一根，切碎后加入适量的盐和水，再放入混合研磨机里研磨，这样你就可以得到一瓶混合辣椒酱了。

我： 没错，让我们把MapReduce的概念应用到食谱上。Map和Reduce其实是两种操作，我来给你详细讲解下。

Map（映射）: 把洋葱、番茄、辣椒和大蒜切碎，是各自作用在这些物体上的一个Map操作。所以你给Map一个洋葱，Map就会把洋葱切碎。 同样的，你把辣椒，大蒜和番茄一一地拿给Map，你也会得到各种碎块。 所以，当你在切像洋葱这样的蔬菜时，你执行就是一个Map操作。 Map操作适用于每一种蔬菜，它会相应地生产出一种或多种碎块，在我们的例子中生产的是蔬菜块。在Map操作中可能会出现有个洋葱坏掉了的情况，你只要把坏洋葱丢了就行了。所以，如果出现坏洋葱了，Map操作就会过滤掉坏洋葱而不会生产出任何的坏洋葱块。

Reduce（化简）:在这一阶段，你将各种蔬菜碎都放入研磨机里进行研磨，你就可以得到一瓶辣椒酱了。这意味要制成一瓶辣椒酱，你得研磨所有的原料。因此，研磨机通常将map操作的蔬菜碎聚集在了一起。

妻子： 所以，这就是MapReduce?

我： 你可以说是，也可以说不是。 其实这只是MapReduce的一部分，MapReduce的强大在于分布式计算。

妻子： 分布式计算？ 那是什么？请给我解释下吧。

我： 没问题。

我： 假设你参加了一个辣椒酱比赛并且你的食谱赢得了最佳辣椒酱奖。得奖之后，辣椒酱食谱大受欢迎，于是你想要开始出售自制品牌的辣椒酱。假设你每天需要生产10000瓶辣椒酱，你会怎么办呢？

妻子： 我会找一个能为我大量提供原料的供应商。

我：是的..就是那样的。那你能否独自完成制作呢？也就是说，独自将原料都切碎？ 仅仅一部研磨机又是否能满足需要？而且现在，我们还需要供应不同种类的辣椒酱，像洋葱辣椒酱、青椒辣椒酱、番茄辣椒酱等等。

妻子： 当然不能了，我会雇佣更多的工人来切蔬菜。我还需要更多的研磨机，这样我就可以更快地生产辣椒酱了。

我：没错，所以现在你就不得不分配工作了，你将需要几个人一起切蔬菜。每个人都要处理满满一袋的蔬菜，而每一个人都相当于在执行一个简单的Map操作。每一个人都将不断的从袋子里拿出蔬菜来，并且每次只对一种蔬菜进行处理，也就是将它们切碎，直到袋子空了为止。

这样，当所有的工人都切完以后，工作台（每个人工作的地方）上就有了洋葱块、番茄块、和蒜蓉等等。

妻子：但是我怎么会制造出不同种类的番茄酱呢？

我：现在你会看到MapReduce遗漏的阶段—搅拌阶段。MapReduce将所有输出的蔬菜碎都搅拌在了一起，这些蔬菜碎都是在以key为基础的 map操作下产生的。搅拌将自动完成，你可以假设key是一种原料的名字，就像洋葱一样。 所以全部的洋葱keys都会搅拌在一起，并转移到研磨洋葱的研磨器里。这样，你就能得到洋葱辣椒酱了。同样地，所有的番茄也会被转移到标记着番茄的研磨器里，并制造出番茄辣椒酱。

披萨终于做好了，她点点头说她已经弄懂什么是MapReduce了。我只希望下次她听到MapReduce时，能更好的理解我到底在做些什么。

编注：下面这段话是网上其他人用最简短的语言解释MapReduce：

> We want to count all the books in the library. You count up shelf #1, I count up shelf #2. That’s map. The more people we get, the faster it goes.

我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。

> Now we get together and add our individual counts. That’s reduce.

现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。

# 什么时候用MapReduce

MapReduce的流行是有理由的。它非常简单、易于实现且扩展性强。大家可以通过它轻易地编写出同时在多台主机上运行的程序，也可以使用Ruby、Python、PHP和C++等非Java类语言编写Map或Reduce程序，还可以在任何安装Hadoop的集群中运行同样的程序，不论这个集群有多少台主机。MapReduce适合处理海量数据，因为它会被多台主机同时处理，这样通常会有较快的速度。

下面的内容来自网络,原文链接 [应该在什么时候使用Hadoop？](http://www.36dsj.com/archives/22748)

有人问我，“你在大数据和Hadoop方面有多少经验？”我告诉他们，我一直在使用Hadoop，但是我处理的数据集很少有大于几个TB的。

他们又问我，“你能使用Hadoop做简单的分组和统计吗？”我说当然可以，我只是告诉他们我需要看一些文件格式的例子。

他们递给我一个包含600MB数据的闪盘，看起来这些数据并非样本数据，由于一些我不能理解的原因，当我的解决方案涉及到pandas.read_csv文件，而不是Hadoop，他们很不愉快。

Hadoop实际上是有很多局限的。

目标：计算图书馆书籍的数量

Map：你统计奇数书架上书的数量，我统计偶数书架上书的数量。（人越多，统计越快）

Reduce：把我们单独统计后的数据加在一起。

我们所做的只有两个：F(k,v)和G(k,v)，除开在中间步骤中的性能优化，一切都是固定的。

它会迫使你在Map中进行所有的计算，分组和统计，执行运算的方式像是穿上了紧身衣，其实很多计算更适合选用其它模型。穿上紧身衣的唯一原因是这可能会扩展到非常大的数据集上，而大多数情况下，你的数据量可能会小几个数量级。

但是由于“大数据”和“Hadoop”这两个热门词，即使很多人实际上不需要Hadoop，他们也愿意穿上“紧身衣”。

一、如果我的数据量是几百兆，Excel可能没法加载它

对于Excel软件来说的“很大的数据”并非大数据，其实还有其它极好的工具可以使用——我喜欢的Pandas。Pandas构建于Numpy库之上，可以以矢量格式的方式有效地把数百兆的数据载入到内存中。在我购买已3年的笔记本上，它可以用Numpy在一眨眼的功夫把1亿的浮点数乘在一起。Matlab和R也是极好的工具。

对于几百兆的数据量，典型的做法是写一个简单的Python脚本按行读取文件行，并处理它，向另一个文件写入。

二、如果我的数据是10GB呢

我买了个新笔记本，它有16GB的内存和256GB的SSD。如果你要载入一个10GB的CSV文件到Pandas，它占用的内存实际上是很小的——其结果是以数字类型的字符串保存的，如“17284832583”作为4字节货8字节的整数，或存储“284572452.2435723”字符串作为8字节的双精度浮点数。

最坏的情况是你或许不能把所有的数据都同时载入到内存中。

三、如果我的数据是100GB、500GB或1TB呢

买个2TB或4TB的硬盘，在桌面PC或服务器上安装一个Postgre来解决它。

四、Hadoop远远比不上SQL或Python脚本

在计算的表达方面，Hadoop弱于SQL，也弱于Python脚本。

SQL是一个很直接的查询语言，适合做业务分析，SQL的查询相当简单，而且还非常快——如果你的数据库使用了正确的索引，二级查询或多级查询另当别论。

Hadoop没有索引的概念，Hadoop只有全表扫描，Hadoop有高度泄露抽象——我花了很多时间来处理Java的内存错误、文件碎片以及集群竞争，这些时间远大于我花在数据分析上的时间。

如果你的数据并不是像SQL表那样的结构化数据（比如纯文本、JSON对象、二进制对象），通常是直接写一个小的Python脚本来按行处理你的数据。把数据存储于文件，处理每一个文件，等等。如果换成是Hadoop就很麻烦。

相比于SQL或Python脚本，Hadoop要慢的多。正确的使用索引后，SQL查询总是非快——PostgreSQL简单的查找索引，检索确切的键值。而Hadoop是全表扫描的，它会把整个表进行重新排序。通过把数据表分片到多台计算机上后，重排序是很快的。另一方面，处理二进制对象，Hadoop需要重复往返于命名节点，目的是查找和处理数据。这适合用Python脚本来实现。

五、我的数据超过了5TB

你应该考虑使用Hadoop，而无需做过多的选择。

使用Hadoop唯一的好处是可伸缩性非常好。如果你有一个包含了数TB数据的表，Hadoop有一个适合全表扫描的选项。如果你没有这样大数据量的表，那么你应该像躲避瘟疫那样避免使用Hadoop。这样使用传统的方法来解决问题会更轻松。

六、Hadoop是一个极好的工具

我并不讨厌Hadoop，当我用其它工具不能很好处理数据时我会选择Hadoop。另外，我推荐使用Scalding，不要使用Hive或Pig。Scalding支持使用Scala语言来编写Hadoop任务链，隐藏了其下的MapReduce。

# MapReduce不是什么

MapReduce不是一种编程语言,而是一种编程范式,不适合mapreduce的例子也很多：

1. 数据规模在TB/PB以下的应用不适合
2. 实时响应的应用不适合
3. 主要数据结构是图或网络的应用不适合。图这样的数据结构中包含着各种隐性的关系， 如图的边、子树 、节点之间的父子关系、权重等，而且这些关系并非都能在图中一个结点上表示。这样的特性就要求处理图的算法要在每一次的迭代计算中加入当前图的完整或部分的信息。 这样的算法基本上用MapReduce的框架是不可能实现的，即便能够实现也会是一种很迂回的解决方案。)
4. 纯数学计算的应用不适合. 一个数学上的例子就是斐波那契数列的计算。 某些机器学习的算法，如梯度和最大期望等，也不是很适合使用MapReduce的模式。




