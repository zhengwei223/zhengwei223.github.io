---
layout: post
title: Hadoop缘起及架构
category: -Hadoop大数据分析平台
tags: Hadoop 大数据 数据挖掘 机器学习
keywords: 蓝桥 lanqiao 教程 Hadoop 大数据 数据挖掘 机器学习
description: 本教程收集hadoop和大数据的相关概念，汇集成册。
author: 郑未
---

# 云计算

云计算，是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机和其他设备，主要是基于互联网的相关服务的增加、使用和交付模式，通常通过互联网来提供动态易扩展且经常是虚拟化的资源。

云是网络、互联网的一种比喻说法。过去在图中往往用云来表示电信网，后来也用来表示互联网和底层基础设施的抽象。狭义云计算指IT基础设施的交付和使用模式，指通过网络以按需、易扩展的方式获得所需资源；广义云计算指服务的交付和使用模式，指通过网络以按需、易扩展的方式获得所需服务。这种服务可以是IT和软件，也可是其他服务。它意味着**计算也可作为一种商品**通过互联网进行流通。

大家知道什么叫做云计算吗？事实上，目前并没有一个确定的定义。然而概括来讲，所谓的云计算，指的就是把你的软件和服务统一部署在数据中心，统一管理，从而实现高伸缩性。
云计算拥有以下特点：

- 虚拟化和自动化
- 服务器，存储介质，网络等资源都可以随时替换
- 所有的资源都由云端统一管理
- 高度的伸缩性以满足业务需求
- 集中于将服务传递给业务

## 云计算的部署方式

从部署方式来说，总共有两类云计算：

- 私有云：数据中心部署在企业内部，由企业自行管理。微软为大家提供了Dynamic Data Center Toolkit，来方便大家管理自己的数据中心。
- 公共云：数据中心由第三方的**云计算供应商**提供，供应商帮助企业管理基础设施（例如硬件，网络，等等）。企业将自己的软件及服务部属在供应商提供的数据中心，并且支付一定的租金。Windows Azure正是这样一个公共云平台,阿里云也是。

## 云计算的运营方式

从运营方式来说，总共有三类云计算：

- 软件即服务（SaaS）：云计算运营商直接以服务的形式供应软件，供最终用户使用。有些服务还提供了SDK，从而使得第三方开发人员可以进行二次开发。在这种运营模式下，开发人员通常只能针对现有的产品开发插件，而无法充分挖掘平台和操作系统的特点，不过他们可以在现有产品的基础上添加新的功能，而不必从头开始实现。微软的Bing，Windows Live，Microsoft Business Productivity Online等产品就属于这一类型。
- 平台即服务（PaaS）：云计算运营商将自己的开发及部署平台提供给第三方开发人员，第三方开发人员在这个平台上开发自己的软件和服务，供自己或其它用户使用。在这种运营模式下，开发人员有了更多的自由，可以发挥出平台的强大功能，而不受现有产品的束缚。Windows Azure正是这样一个产品。
- 基础设施即服务（IaaS）：云计算运营商提供但不管理基础设施，第三方开发人员将开发好的软件和服务交给自己公司的IT管理员，由IT管理员负责部署及管理。在这种运营模式下，开发人员和IT管理员有最大限度的自由，然而由于必须自行管理部分基础设施，因此成本通常也会较大，对管理员的要求也会较高。目前微软尚未提供IaaS的云计算运营模式，不过我们正在考虑如何给予开发人员和IT管理员更多的自由。


总结 云计算指的就是把你的软件和服务统一部署在数据中心，统一管理，从而实现高伸缩性。从部署方式来说，云计算可以分为私有云和公共云。从运营方式来说，云计算可以分成SaaS，PaaS，IaaS三类。

# 大数据

大数据的4V特征：

- 数据量大，TB->PB
- 数据类型繁多，结构化、非结构化文本、日志、视频、图片、地理位置等；
- 商业价值高，但是这种价值需要在海量数据之上，通过数据分析与机器学习更快速的挖掘出来；
- 处理时效性高，海量数据的处理需求不再局限在离线计算当中。

# hadoop

## hadoop是什么？

(1)Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。Hadoop=HDFS（文件系统，数据存储技术相关）+ Mapreduce（数据处理），Hadoop的数据来源可以是任何形式，在处理半结构化和非结构化数据上与关系型数据库相比有更好的性能，具有更灵活的处理能力，不管任何数据形式最终会转化为key/value，key/value是基本数据单元。用函数式变成Mapreduce代替SQL，SQL是查询语句，而Mapreduce则是使用脚本和代码，而对于适用于关系型数据库，习惯SQL的Hadoop有开源工具hive代替。

(2)Hadoop就是一个分布式计算的解决方案.

## hadoop能做什么？

  hadoop擅长日志分析，facebook就用Hive来进行日志分析，2009年时facebook就有非编程人员的30%的人使用HiveQL进行数据分析；淘宝搜索中    的 自定义筛选也使用的Hive；利用Pig还可以做高级的数据处理，包括Twitter、LinkedIn 上用于发现您可能认识的人，可以实现类似Amazon.com的协同过滤的推荐效果。淘宝的商品推荐也是！在Yahoo！的40%的Hadoop作业是用pig运行的，包括垃圾邮件的识别和过滤，还有用户特征建模。（2012年8月25新更新，天猫的推荐系统是hive，少量尝试mahout！）

  下面举例说明：

  设想一下这样的应用场景. 我有一个100M 的数据库备份的sql 文件.我现在想在不导入到数据库的情况下直接用grep操作通过正则过滤出我想要的内容。例如：某个表中 含有相同关键字的记录那么有几种方式,一种是直接用linux的命令 grep 还有一种就是通过编程来读取文件,然后对每行数据进行正则匹配得到结果好了 现在是100M 的数据库备份.上述两种方法都可以轻松应对.

那么如果是1G , 1T 甚至 1PB 的数据呢 ,上面2种方法还能行得通吗？ 

答案是不能.毕竟单台服务器的性能总有其上限.那么对于这种超大数据文件怎么得到我们想要的结果呢？

有种方法 就是分布式计算, 分布式计算的核心就在于 利用分布式算法 把运行在单台机器上的程序扩展到多台机器上并行运行.从而使数据处理能力成倍增加.但是这种分布式计算一般对编程人员要求很高,而且对服务器也有要求.导致了成本变得非常高.

Haddop 就是为了解决这个问题诞生的.Haddop 可以很轻易的把 很多linux的廉价pc 组成 分布式结点,然后编程人员也不需要知道分布式算法之类,只需要根据mapreduce的规则定义好接口方法,剩下的就交给Haddop. 它会自动把相关的计算分布到各个结点上去,然后得出结果.

例如上述的例子 ： Hadoop 要做的事 首先把 1PB的数据文件导入到 HDFS中, 然后编程人员定义好 map和reduce, 也就是把文件的行定义为key,每行的内容定义为value , 然后进行正则匹配,匹配成功则把结果 通过reduce聚合起来返回.Hadoop 就会把这个程序分布到N 个结点去并行的操作.

那么原本可能需要计算好几天,在有了足够多的结点之后就可以把时间缩小到几小时之内.


这也就是所谓的 大数据 云计算了.如果还是不懂的话再举个简单的例子

比如  1亿个  1 相加 得出计算结果, 我们很轻易知道结果是 1亿.但是计算机不知道.那么单台计算机处理的方式做一个一亿次的循环每次结果+1

那么分布式的处理方式则变成 我用 1万台 计算机,每个计算机只需要计算 1万个 1 相加 然后再有一台计算机把 1万台计算机得到的结果再相加
从而得到最后的结果.理论上讲, 计算速度就提高了 1万倍. 

当然上面可能是一个不恰当的例子.但所谓分布式,大数据,云计算 大抵也就是这么回事了.


## hadoop能为我司做什么？

零数据基础，零数据平台，一切起点都是0。

- 日志处理
- 用户细分特征建模
- 个性化广告推荐
- 智能仪器推荐
- 一切以增加企业的商业价值为核心目的、最终目的